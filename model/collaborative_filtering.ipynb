{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils import core\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import ivy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 loss 0.13842763006687164\n",
      "step 1 loss 0.13815009593963623\n",
      "step 2 loss 0.13794763386249542\n",
      "step 3 loss 0.1377740204334259\n",
      "step 4 loss 0.13761824369430542\n",
      "step 5 loss 0.13747404515743256\n",
      "step 6 loss 0.13733619451522827\n",
      "step 7 loss 0.13720263540744781\n",
      "step 8 loss 0.13707198202610016\n",
      "step 9 loss 0.13694332540035248\n",
      "step 10 loss 0.1368159055709839\n",
      "step 11 loss 0.13668924570083618\n",
      "step 12 loss 0.13656292855739594\n",
      "step 13 loss 0.1364365816116333\n",
      "step 14 loss 0.13630998134613037\n",
      "step 15 loss 0.13618285953998566\n",
      "step 16 loss 0.1360551118850708\n",
      "step 17 loss 0.1359264850616455\n",
      "step 18 loss 0.1357969492673874\n",
      "step 19 loss 0.13566631078720093\n",
      "step 20 loss 0.13553455471992493\n",
      "step 21 loss 0.13540160655975342\n",
      "step 22 loss 0.13526731729507446\n",
      "step 23 loss 0.13513177633285522\n",
      "step 24 loss 0.13499481976032257\n",
      "step 25 loss 0.1348564326763153\n",
      "step 26 loss 0.13471661508083344\n",
      "step 27 loss 0.13457532227039337\n",
      "step 28 loss 0.13443253934383392\n",
      "step 29 loss 0.1342882513999939\n",
      "step 30 loss 0.13414250314235687\n",
      "step 31 loss 0.1339951604604721\n",
      "step 32 loss 0.13384631276130676\n",
      "step 33 loss 0.13369596004486084\n",
      "step 34 loss 0.13354407250881195\n",
      "step 35 loss 0.1333906650543213\n",
      "step 36 loss 0.13323570787906647\n",
      "step 37 loss 0.13307926058769226\n",
      "step 38 loss 0.13292133808135986\n",
      "step 39 loss 0.1327618807554245\n",
      "step 40 loss 0.13260097801685333\n",
      "step 41 loss 0.13243860006332397\n",
      "step 42 loss 0.13227474689483643\n",
      "step 43 loss 0.13210946321487427\n",
      "step 44 loss 0.1319427639245987\n",
      "step 45 loss 0.1317746341228485\n",
      "step 46 loss 0.1316051334142685\n",
      "step 47 loss 0.13143424689769745\n",
      "step 48 loss 0.131261944770813\n",
      "step 49 loss 0.13108836114406586\n",
      "step 50 loss 0.13091342151165009\n",
      "step 51 loss 0.13073715567588806\n",
      "step 52 loss 0.13055962324142456\n",
      "step 53 loss 0.13038085401058197\n",
      "step 54 loss 0.13020074367523193\n",
      "step 55 loss 0.1300194412469864\n",
      "step 56 loss 0.12983690202236176\n",
      "step 57 loss 0.1296531707048416\n",
      "step 58 loss 0.12946827709674835\n",
      "step 59 loss 0.12928220629692078\n",
      "step 60 loss 0.1290949583053589\n",
      "step 61 loss 0.12890659272670746\n",
      "step 62 loss 0.12871713936328888\n",
      "step 63 loss 0.12852656841278076\n",
      "step 64 loss 0.12833498418331146\n",
      "step 65 loss 0.12814228236675262\n",
      "step 66 loss 0.12794853746891022\n",
      "step 67 loss 0.12775377929210663\n",
      "step 68 loss 0.12755805253982544\n",
      "step 69 loss 0.12736128270626068\n",
      "step 70 loss 0.1271635740995407\n",
      "step 71 loss 0.12696489691734314\n",
      "step 72 loss 0.12676529586315155\n",
      "step 73 loss 0.12656475603580475\n",
      "step 74 loss 0.12636332213878632\n",
      "step 75 loss 0.12616102397441864\n",
      "step 76 loss 0.12595780193805695\n",
      "step 77 loss 0.1257537603378296\n",
      "step 78 loss 0.1255488395690918\n",
      "step 79 loss 0.12534315884113312\n",
      "step 80 loss 0.1251366138458252\n",
      "step 81 loss 0.1249292641878128\n",
      "step 82 loss 0.12472118437290192\n",
      "step 83 loss 0.12451230734586716\n",
      "step 84 loss 0.1243027001619339\n",
      "step 85 loss 0.12409235537052155\n",
      "step 86 loss 0.1238812580704689\n",
      "step 87 loss 0.12366946041584015\n",
      "step 88 loss 0.12345700711011887\n",
      "step 89 loss 0.12324386090040207\n",
      "step 90 loss 0.12303003668785095\n",
      "step 91 loss 0.12281554192304611\n",
      "step 92 loss 0.12260044366121292\n",
      "step 93 loss 0.1223846822977066\n",
      "step 94 loss 0.12216833233833313\n",
      "step 95 loss 0.1219513863325119\n",
      "step 96 loss 0.12173384428024292\n",
      "step 97 loss 0.12151570618152618\n",
      "step 98 loss 0.12129701673984528\n",
      "step 99 loss 0.12107782065868378\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "# sample ivy test\n",
    "class MyModel(ivy.Module):\n",
    "    def __init__(self):\n",
    "        self.linear0 = ivy.Linear(3, 64)\n",
    "        self.linear1 = ivy.Linear(64, 1)\n",
    "        ivy.Module.__init__(self)\n",
    "\n",
    "    def _forward(self, x):\n",
    "        x = ivy.relu(self.linear0(x))\n",
    "        return ivy.sigmoid(self.linear1(x))\n",
    "\n",
    "ivy.set_framework('torch')  # change to any preffered framework!\n",
    "model = MyModel()\n",
    "optimizer = ivy.Adam(1e-4)\n",
    "x_in = ivy.array([1., 2., 3.])\n",
    "target = ivy.array([0.])\n",
    "\n",
    "def loss_fn(v):\n",
    "    out = model(x_in, v=v)\n",
    "    return ivy.reduce_mean((out - target)**2)\n",
    "\n",
    "for step in range(100):\n",
    "    loss, grads = ivy.execute_with_gradients(loss_fn, model.v)\n",
    "    model.v = optimizer.step(model.v, grads)\n",
    "    print('step {} loss {}'.format(step, ivy.to_numpy(loss).item()))\n",
    "\n",
    "print('Finished training!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1695f3ba5904c8d6995ae81525dd77f96d1a9b2ae6aa06a0b9c9567c6e75ff61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
